# Vision-Papers

This is a _non-exhaustive_ repo of papers I've read as a student at UC San Diego, Carnegie Mellon, and professionally as a computer vision engineer / intern, mostly for personal reference. It probably won't be very beneficial to the general public aside from giving a sense of what the average computer vision engineer reads through. 

Many papers that are standard deep learning / computer vision course material (optimizers, learning rate schedules, special activations or convolutions) are omitted, as are papers that I just don't remember at the time of writing this. 

If you're a recruiter, questions about papers from this list are game :) 

### Classical

(2004) SIFT: [Distinctive Image Features from Scale-Invariant Keypoints](https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf)

(2005) HOG: [Histograms of Oriented Gradients for Human Detection](https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf)

(2011) Line2D / LineMOD: [Gradient Response Maps for Real-Time Detection of Texture-Less Objects](http://campar.in.tum.de/pub/hinterstoisser2011pami/hinterstoisser2011pami.pdf)

(2012) ORB: [an efficient alternative to SIFT or SURF](http://www.gwylab.com/download/ORB_2012.pdf)

(2013) BOLD: [features to detect texture-less objects](https://openaccess.thecvf.com/content_iccv_2013/papers/Tombari_BOLD_Features_to_2013_ICCV_paper.pdf)

(2013) R-CNN: [Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/abs/1311.2524)

### 2015 

ResNet: [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)

Faster R-CNN: [Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497)

SSD: [Single Shot MultiBox Detector](https://arxiv.org/abs/1512.023250)

YOLOv1: [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.026400)

Batch Normalization: [Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)

U-Net: [Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)

### 2016

SiamFC: [Fully-Convolutional Siamese Networks for Object Tracking](https://arxiv.org/abs/1606.09549)

BiGAN: [Adversarial Feature Learning](https://arxiv.org/abs/1605.09782)

ResNeXt: [Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/abs/1611.05431)

DenseNet: [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993)

Layer Norm: [Layer Normalization](https://arxiv.org/abs/1607.06450)

Weight Normalization: [A Simple Reparameterization to Accelerate Training of Deep Neural Networks](https://arxiv.org/abs/1602.07868)

Learning [without Forgetting](https://arxiv.org/abs/1606.09282)

### 2017

CycleGaN: [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/abs/1703.10593)

RetinaNet: [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002)

LARS: [Large Batch Training of Convolutional Networks](https://arxiv.org/abs/1708.03888)

MixUp: [Beyond Empirical Risk Minimization](https://arxiv.org/abs/1710.09412)

NIMA: [Neural Image Assessment](https://arxiv.org/abs/1709.05424)

Swish: [Searching for Activation Functions](https://arxiv.org/abs/1710.05941)

SENet: [Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507)

Cut, Paste and Learn: [Surprisingly Easy Synthesis for Instance Detection](https://arxiv.org/abs/1708.01642)

Mask R-CNN: [Mask R-CNN](https://arxiv.org/abs/1703.06870)

DeepLabv3: [Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1706.05587)

Soft-NMS: [Improving Object Detection With One Line of Code](https://arxiv.org/abs/1704.04503)

Transformer: [Attention Is All You Need](https://arxiv.org/abs/1706.03762)

### 2018 

SiamRPN: [High Performance Visual Tracking with Siamese Region Proposal Network](http://www.zhengzhu.net/upload/P6938bc861e8d4583bf47d47d64ed9598.pdf)

CBAM: [Convolutional Block Attention Module](https://arxiv.org/abs/1807.06521) 

MnasNet: [Platform-Aware Neural Architecture Search for Mobile](https://arxiv.org/abs/1807.11626)

MobileNetV2: [Inverted Residuals and Linear Bottlenecks](https://arxiv.org/abs/1801.04381)

YOLOv3:  [An Incremental Improvement](https://arxiv.org/abs/1804.02767)

GANomaly: [Semi-Supervised Anomaly Detection via Adversarial Training](https://arxiv.org/abs/1805.06725)

DeepSVDD: [Deep One-Class Classification](http://data.bit.uni-bonn.de/publications/ICML2018.pdf)

PVNet: [PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation](https://arxiv.org/abs/1812.11788) 

SWA: [Averaging Weights Leads to Wider Optima and Better Generalization](https://arxiv.org/abs/1803.05407)

DropBlock: [DropBlock: A regularization method for convolutional networks](https://arxiv.org/abs/1810.12890)

### 2019 

D2-Net: [A Trainable CNN for Joint Detection and Description of Local Features](https://arxiv.org/abs/1905.03561) 

CORAL: [Rank consistent ordinal regression for neural networks with application to age estimation](https://arxiv.org/abs/1901.07884)

SiamRPN++: [Evolution of Siamese Visual Tracking with Very Deep Networks](https://arxiv.org/abs/1812.11703)

QATM: [Quality-Aware Template Matching For Deep Learning](https://arxiv.org/abs/1903.07254)

MobileNetv3: [Searching for MobileNetV3](https://arxiv.org/abs/1905.02244) 

SKNet: [Selective Kernel Networks](https://arxiv.org/abs/1903.06586)

MS R-CNN: [Mask Scoring R-CNN](https://arxiv.org/abs/1903.00241) 

EfficientNet: [https://arxiv.org/abs/1903.00241](https://arxiv.org/abs/1905.11946) 

Mish: [A Self Regularized Non-Monotonic Activation Function](https://arxiv.org/abs/1908.08681)

MOCO: [Momentum Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/abs/1911.05722)

CutMix: [Regularization Strategy to Train Strong Classifiers with Localizable Features](https://arxiv.org/abs/1905.04899)

GIoU: [Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression](https://arxiv.org/abs/1902.09630)


### 2020

FCDD: [Explainable Deep One-Class Classification](https://arxiv.org/abs/2007.01760)

MOCOv2: [Improved Baselines with Momentum Contrastive Learning](https://arxiv.org/abs/2003.04297)

SCAN: [Learning to Classify Images without Labels](https://arxiv.org/abs/2005.12320) 

SimCLR: [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/abs/2002.05709)

SimCLRv2: [Big Self-Supervised Models are Strong Semi-Supervised Learners](https://arxiv.org/abs/2006.10029)

SimSiam: [Exploring Simple Siamese Representation Learning](https://arxiv.org/abs/2011.10566)

SwAV: [Unsupervised Learning of Visual Features by Contrasting Cluster Assignments](https://arxiv.org/abs/2006.09882)

YOLOv4: [Optimal Speed and Accuracy of Object Detection](https://arxiv.org/abs/2004.10934)

ViT: [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)

DETR: [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)

PaDiM: [a Patch Distribution Modeling Framework for Anomaly Detection and Localization](https://arxiv.org/abs/2011.08785)

FairMOT: [On the Fairness of Detection and Re-Identification in Multiple Object Tracking](https://arxiv.org/abs/2004.01888)

### 2021

Barlow Twins: [Self-Supervised Learning via Redundancy Reduction](https://arxiv.org/abs/2103.03230)

DINO: [Emerging Properties in Self-Supervised Vision Transformers](https://arxiv.org/abs/2104.14294)


